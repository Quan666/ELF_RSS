import asyncio
import base64
import os
import uuid

import httpx
import nonebot
from apscheduler.triggers.interval import IntervalTrigger
from nonebot import logger, require
from qbittorrent import Client
from starlette.responses import FileResponse
from ..config import config

# è®¡åˆ’
# åˆ›å»ºä¸€ä¸ªå…¨å±€å®šæ—¶å™¨ç”¨æ¥æ£€æµ‹ç§å­ä¸‹è½½æƒ…å†µ
# ç¾¤æ–‡ä»¶ä¸Šä¼ æˆåŠŸå›è°ƒ
# æ–‡ä»¶ä¸‰ç§çŠ¶æ€1.ä¸‹è½½ä¸­2ã€‚ä¸Šä¼ ä¸­3.ä¸Šä¼ å®Œæˆ
# æ–‡ä»¶ä¿¡æ¯æŒä¹…åŒ–å­˜å‚¨
# å…³é”®è¯æ­£åˆ™è¡¨è¾¾å¼
# ä¸‹è½½å¼€å…³


app = nonebot.get_asgi()


@app.get("/elfrss/file/{filename}")
async def file(filename: str) -> FileResponse:
    path = (await get_qb()).get_default_save_path()
    return FileResponse(path=path + os.sep + filename, filename=filename)


async def send_Msg(msg: str):
    logger.info(msg)
    bot, = nonebot.get_bots().values()
    for group_id in config.down_status_msg_group:
        await bot.send_msg(message_type='group', group_id=int(group_id), message=msg)


async def get_qb():
    try:
        qb = Client(config.qb_web_url)
        qb.login()
    except BaseException as e:
        bot, = nonebot.get_bots().values()
        msg = 'âŒ æ— æ³•è¿æ¥åˆ° qbittorrent ,è¯·æ£€æŸ¥ï¼š\n1.æ˜¯å¦å¯åŠ¨ç¨‹åº\n2.æ˜¯å¦å‹¾é€‰äº†â€œWebç”¨æˆ·ç•Œé¢ï¼ˆè¿œç¨‹æ§åˆ¶ï¼‰â€\n3.è¿æ¥åœ°å€ã€ç«¯å£æ˜¯å¦æ­£ç¡®\nE: {}'.format(e)
        logger.error(msg)
        await bot.send_msg(message_type='private', user_id=str(list(config.superusers)[0]), message=msg)
        return None
    try:
        qb.get_default_save_path()
    except BaseException as e:
        bot, = nonebot.get_bots().values()
        msg = 'âŒ æ— æ³•è¿ç™»å½•åˆ° qbittorrent ,è¯·æ£€æŸ¥æ˜¯å¦å‹¾é€‰ â€œå¯¹æœ¬åœ°ä¸»æœºä¸Šçš„å®¢æˆ·ç«¯è·³è¿‡èº«ä»½éªŒè¯â€ã€‚\nE: {}'.format(
            e)
        logger.error(msg)
        await bot.send_msg(message_type='private', user_id=str(list(config.superusers)[0]), message=msg)
        return None
    return qb


def getSize(size: int) -> str:
    kb = 1024
    mb = kb * 1024
    gb = mb * 1024
    tb = gb * 1024

    if size >= tb:
        return "%.2f TB" % float(size / tb)
    if size >= gb:
        return "%.2f GB" % float(size / gb)
    if size >= mb:
        return "%.2f MB" % float(size / mb)
    if size >= kb:
        return "%.2f KB" % float(size / kb)


def get_torrent_b16Hash(content: bytes) -> str:
    import magneturi
    # mangetlink = magneturi.from_torrent_file(torrentname)
    mangetlink = magneturi.from_torrent_data(content)
    # print(mangetlink)
    ch = ''
    n = 20
    b32Hash = n * ch + mangetlink[20:52]
    # print(b32Hash)
    b16Hash = base64.b16encode(base64.b32decode(b32Hash))
    b16Hash = b16Hash.lower()
    b16Hash = str(b16Hash, "utf-8")
    # print("40ä½info hashå€¼ï¼š" + '\n' + b16Hash)
    # print("ç£åŠ›é“¾ï¼š" + '\n' + "magnet:?xt=urn:btih:" + b16Hash)
    return b16Hash


async def get_Hash_Name(url: str, proxy=None) -> dict:
    if not proxy:
        proxy = {}
    qb = await get_qb()
    info = None
    async with httpx.AsyncClient(proxies=proxy) as client:
        try:
            res = await client.get(url, timeout=100)
            qb.download_from_file(res.content)
            hash = get_torrent_b16Hash(res.content)
            while not info:
                for tmp_torrent in qb.torrents():
                    if tmp_torrent['hash'] == hash:
                        info = {
                            'hash': tmp_torrent['hash'],
                            'filename': tmp_torrent['name'],
                            'size': getSize(tmp_torrent['size'])
                        }
                await asyncio.sleep(1)
        except Exception as e:
            await send_Msg('ä¸‹è½½ç§å­å¤±è´¥,å¯èƒ½éœ€è¦ä»£ç†:{}'.format(e))
    return info


# ç§å­åœ°å€ï¼Œç§å­ä¸‹è½½è·¯å¾„ï¼Œç¾¤æ–‡ä»¶ä¸Šä¼  ç¾¤åˆ—è¡¨ï¼Œè®¢é˜…åç§°
async def start_down(url: str, path: str, group_ids: list, name: str, proxy=None):
    qb = await get_qb()
    if not qb:
        return
    # è·å–ç§å­ hash
    info = await get_Hash_Name(url=url, proxy=proxy)
    await rss_trigger(hash=info['hash'], group_ids=group_ids,
                      name='è®¢é˜…ï¼š{}\n{}\næ–‡ä»¶å¤§å°ï¼š{}'.format(name, info['filename'], info['size']))


async def check_down_status(hash: str, group_ids: list, name: str):
    qb = await get_qb()
    if not qb:
        return
    info = qb.get_torrent(hash)
    files = qb.get_torrent_files(hash)
    bot, = nonebot.get_bots().values()
    if info['total_downloaded'] - info['total_size'] >= 0.000000:
        await send_Msg(str('ğŸ‘ {}\nHash: {} \nä¸‹è½½å®Œæˆï¼'.format(name, hash)))
        for group_id in group_ids:
            for tmp in files:
                # å¼‚å¸¸åŒ…èµ·æ¥é˜²æ­¢è¶…æ—¶æŠ¥é”™å¯¼è‡´åç»­ä¸æ‰§è¡Œ
                try:
                    if config.local_ip and len(config.local_ip) >= 7:
                        # é€šè¿‡è¿™ä¸ªAPIä¸‹è½½çš„æ–‡ä»¶èƒ½ç›´æ¥æ”¾å…¥CQç ä½œä¸ºå›¾ç‰‡æˆ–è¯­éŸ³å‘é€ è°ƒç”¨åä¼šé˜»å¡ç›´åˆ°ä¸‹è½½å®Œæˆåæ‰ä¼šè¿”å›æ•°æ®ï¼Œè¯·æ³¨æ„ä¸‹è½½å¤§æ–‡ä»¶æ—¶çš„è¶…æ—¶
                        await send_Msg('go-cqhttp å¼€å§‹ä¸‹è½½æ–‡ä»¶ï¼š{}'.format(tmp['name']))
                        path = (await bot.call_api('download_file',
                                                   url='http://{}:8080/elfrss/file/{}'.format(config.local_ip,
                                                                                              tmp['name']))).file
                    else:
                        path = info['save_path'] + tmp['name']
                    await send_Msg(str('{}\nHash: {} \nå¼€å§‹ä¸Šä¼ åˆ°ç¾¤ï¼š{}'.format(name, hash, group_id)))
                    await bot.call_api('upload_group_file', group_id=group_id, file=path, name=tmp['name'])
                except:
                    continue
        scheduler = require("nonebot_plugin_apscheduler").scheduler
        scheduler.remove_job(hash)
    else:
        await send_Msg(str('{}\nHash: {} \nä¸‹è½½äº† {}%\nå¹³å‡ä¸‹è½½é€Ÿåº¦ï¼š{} KB/s'.format(name, hash, round(
            info['total_downloaded'] / info['total_size'] * 100, 2), round(info['dl_speed_avg'] / 1024, 2))))


async def rss_trigger(hash: str, group_ids: list, name: str):
    scheduler = require("nonebot_plugin_apscheduler").scheduler
    # åˆ¶ä½œä¸€ä¸ªâ€œtimeåˆ†é’Ÿ/æ¬¡â€è§¦å‘å™¨
    trigger = IntervalTrigger(
        # minutes=1,
        seconds=int(config.down_status_msg_date),
        jitter=10
    )
    job_defaults = {'max_instances': 10}
    # æ·»åŠ ä»»åŠ¡
    scheduler.add_job(
        func=check_down_status,  # è¦æ·»åŠ ä»»åŠ¡çš„å‡½æ•°ï¼Œä¸è¦å¸¦å‚æ•°
        trigger=trigger,  # è§¦å‘å™¨
        args=(hash, group_ids, name),  # å‡½æ•°çš„å‚æ•°åˆ—è¡¨ï¼Œæ³¨æ„ï¼šåªæœ‰ä¸€ä¸ªå€¼æ—¶ï¼Œä¸èƒ½çœç•¥æœ«å°¾çš„é€—å·
        id=hash,
        # kwargs=None,
        misfire_grace_time=60,  # å…è®¸çš„è¯¯å·®æ—¶é—´ï¼Œå»ºè®®ä¸è¦çœç•¥
        # jobstore='default',  # ä»»åŠ¡å‚¨å­˜åº“ï¼Œåœ¨ä¸‹ä¸€å°èŠ‚ä¸­è¯´æ˜
        job_defaults=job_defaults,
    )
    await send_Msg(str('ğŸ‘ {}\nHash: {} \nä¸‹è½½ä»»åŠ¡æ·»åŠ æˆåŠŸï¼'.format(name, hash)))
